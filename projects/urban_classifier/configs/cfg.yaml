# Here's where you define experiment-specific hyperparameters.
# You can also create lists and group parameters together into nested sub-parts.
# In Python, this is all read as a dict.

# environment/computational parameters
seed: 32678456782       # random number generator seed (long integer value)
device: cuda 
num_workers: 6

# dataset parameters
data_root: '/datadrive/animals_training_dataset'
num_classes: 19

# training hyperparameters
image_size: [224, 224]
num_epochs: 200
batch_size: 128 ##it was 1 with random, tried 32 bs way faster tried 128 and only 10sec faster per epoc
learning_rate: 0.001
weight_decay: 0.001

log_dir: 'logs/urban_wildlife_across_loc_transf_curriculum' #or split_by_loc split_across_loc or random_split (already ran)
split_type: 'split_across_loc' #or split_across_loc or split_random
model_dir: 'model_states/split_across_loc_transf_curriculum'

##data augmentation
#curriculum learning, max numb of images per class
max_num: [100, 100, 100, 100, 100, 200, 200, 200, 200, 200, 500, 500, 500, 500, 500, 1000, 1000, 1000, 1000, 1000, 2000] #this could be an incremental list that increases the number of images use as epoch increases